# Awesome Face Reenactment/Talking Face Generation

## Survey

- <a name="todo"></a> The Creation and Detection of Deepfakes: A Survey (**arXiv 2020**) [[paper](https://arxiv.org/abs/2004.11138)] 
- <a name="todo"></a> DeepFakes and Beyond: A Survey of Face Manipulation and Fake Detection (**arXiv 2020**) [[paper](https://arxiv.org/abs/2001.00179)]
- <a name="todo"></a> A Review on Face Reenactment Techniques (**I4Tech 2020**) [[paper](https://ieeexplore.ieee.org/document/9102668)]
- <a name="todo"></a> What comprises a good talking-head video generation?: A Survey and Benchmark (**arXiv 2020**) [[paper](https://arxiv.org/abs/2005.03201)] 
- <a name="todo"></a> Deep Audio-Visual Learning: A Survey (**arXiv 2020**) [[paper](http://arxiv.org/abs/2001.04758)] 



## Talking Face Generation Papers

### 2022
- <a name="todo"></a> One-shot Talking Face Generation from Single-speaker Audio-Visual Correlation Learning (**AAAI, 2022**) [[paper](http://arxiv.org/abs/2112.02749)] 
- <a name="todo"></a> Latent Image Animator: Learning to Animate Images via Latent Space Navigation (**ICLR, 2022**) [[paper](https://openreview.net/pdf?id=7r6kDq0mK_)] 
- <a name="todo"></a> Finding Directions in GAN’s Latent Space for Neural Face Reenactment (**Arxiv, 2022**) [[paper](https://arxiv.org/pdf/2202.00046.pdf
)] 


### 2021
- <a name="todo"></a> Talking Head Generation with Audio and Speech Related Facial Action Units (**BMVC, 2021**) [[paper](http://arxiv.org/abs/2110.09951)] 
- <a name="todo"></a> 3D Talking Face with Personalized Pose Dynamics (**TVCG, 2021**) [[paper](https://personal.utdallas.edu/~xxg061000/TVCG2021.pdf)] 
- <a name="todo"></a> Talking Head Generation with Audio and Speech Related Facial Action Units (**BMVC, 2021**) [[paper](http://arxiv.org/abs/2110.09951)] 
- <a name="todo"></a> FACIAL: Synthesizing Dynamic Talking Face with Implicit Attribute Learning (**ICCV, 2021**) [[paper](http://arxiv.org/abs/2108.07938)] 
- <a name="todo"></a> AD-NeRF: Audio Driven Neural Radiance Fields for Talking Head Synthesis (**ICCV, 2021**) [[paper](http://arxiv.org/abs/2103.11078)] 
- <a name="todo"></a> Audio2Head: Audio-driven One-shot Talking-head Generation with Natural Head Motion (**IJCAI, 2021**) [[paper](http://arxiv.org/abs/2107.09293)] 
- <a name="todo"></a> Flow-Guided One-Shot Talking Face Generation With a High-Resolution Audio-Visual Dataset (**CVPR, 2021**) [[paper](https://openaccess.thecvf.com/content/CVPR2021/papers/Zhang_Flow-Guided_One-Shot_Talking_Face_Generation_With_a_High-Resolution_Audio-Visual_Dataset_CVPR_2021_paper.pdf)] 
- <a name="todo"></a> Pose-Controllable Talking Face Generation by Implicitly Modularized Audio-Visual Representation (**CVPR, 2021**) [[paper](https://arxiv.org/abs/2104.11116)] [[code](https://github.com/Hangz-nju-cuhk/Talking-Face_PC-AVS)]
- <a name="todo"></a> Audio-Driven Emotional Video Portraits (**CVPR, 2021**) [[paper](http://arxiv.org/abs/2104.07452)] [[code](https://github.com/jixinya/EVP)]
- <a name="todo"></a> Everything's Talkin': Pareidolia Face Reenactment (**CVPR, 2021**) [[paper](http://arxiv.org/abs/2104.03061)] 
- <a name="todo"></a> APB2FaceV2: Real-Time Audio-Guided Multi-Face Reenactment (**ICASSP, 2021**) [[paper](https://arxiv.org/abs/2010.13017v1)] [[code](https://github.com/zhangzjn/APB2FaceV2)]

### 2020
- <a name="todo"></a> MEAD: A Large-Scale Audio-Visual Dataset for Emotional Talking-Face Generation (**ECCV, 2020**) [[paper](http://link.springer.com/10.1007/978-3-030-58589-1_42)] [[code](https://github.com/uniBruce/Mead)]
- <a name="todo"></a> A Lip Sync Expert Is All You Need for Speech to Lip Generation In The Wild (**MM, 2020**) [[paper](http://arxiv.org/abs/2008.10010)] [[code](https://github.com/Rudrabha/Wav2Lip)]
- <a name="todo"></a> Arbitrary Talking Face Generation via Attentional Audio-Visual Coherence Learning (**IJCAI, 2020**) [[paper](http://arxiv.org/abs/1812.06589)] 
- <a name="todo"></a> APB2Face: Audio-guided face reenactment with auxiliary pose and blink signals (**ICASSP, 2020**) [[paper](https://arxiv.org/abs/2004.14569v1)] [[code](https://github.com/zhangzjn/APB2Face)]
- <a name="todo"></a> MakeItTalk: Speaker-Aware Talking Head Animation (**SIGGRAPH ASIA, 2020**) [[paper](http://arxiv.org/abs/2004.12992)] [[code](https://github.com/yzhou359/MakeItTalk)]
- <a name="todo"></a> Everybody’s Talkin’: Let Me Talk as You Want (**arXiv, 2020**) [[paper](http://arxiv.org/abs/2001.05201)] 


### 2019
- <a name="todo"></a> Talking Face Generation by Adversarially Disentangled Audio-Visual Representation(**AAAI, 2019**) [[paper](http://arxiv.org/abs/1807.07860)]
- <a name="todo"></a> Towards Automatic Face-to-Face Translation (**MM, 2019**) [[paper](http://arxiv.org/abs/2003.00418)] [[code](https://github.com/Rudrabha/LipGAN)]
- <a name="todo"></a> Few-Shot Adversarial Learning of Realistic Neural Talking Head Models (**ICCV, 2019**) [[paper](http://arxiv.org/abs/1905.08233)] 
- <a name="todo"></a> Learning the Face Behind a Voice (**CVPR, 2019**) [[paper](https://ieeexplore.ieee.org/document/8953196/)] [[code](https://github.com/saiteja-talluri/Speech2Face)]
- <a name="todo"></a> Hierarchical Cross-Modal Talking Face Generation with Dynamic Pixel-Wise Loss (**CVPR, 2019**) [[paper](http://arxiv.org/abs/1905.03820)] [[code](https://github.com/lelechen63/ATVGnet)]
- <a name="todo"></a> Wav2Pix: Speech-conditioned Face Generation using Generative Adversarial Networks (**ICASSP, 2019**) [[paper](http://arxiv.org/abs/1903.10195)] [[code](https://github.com/miqueltubau/Wav2Pix)]
- <a name="todo"></a> Face Reconstruction from Voice using Generative Adversarial Networks (**NIPS, 2019**) [[paper](https://papers.nips.cc/paper/8768-face-reconstruction-from-voice-using-generative-adversarial-networks.pdf)] 

### 2018
- <a name="todo"></a> Lip movements generation at a glance (**ECCV, 2018**) [[paper](https://arxiv.org/abs/1803.10404)]

### 2017

- <a name="todo"></a> Synthesizing Obama: learning lip sync from audio (**TOG, 2017**) [[paper](https://dl.acm.org/doi/10.1145/3072959.3073640)] 
- <a name="todo"></a> You said that? (**BMVC, 2017**) [[paper](http://arxiv.org/abs/1705.02966)] [[code](https://github.com/joonson/yousaidthat)]













## Face Reenactment Papers

### 2021
- <a name="todo"></a> PIRenderer: Controllable Portrait Image Generation via Semantic Neural Rendering (**ICCV, 2021**) [[paper](http://arxiv.org/abs/2109.08379)] 
- <a name="todo"></a> LI-Net: Large-Pose Identity-Preserving Face Reenactment Network (**ICME, 2021**) [[paper](https://arxiv.org/pdf/2104.02850)] 
- <a name="todo"></a> One-shot Face Reenactment Using Appearance Adaptive Normalization (**AAAI, 2021**) [[paper](https://arxiv.org/pdf/2102.03984.pdf)] 

### 2020
- <a name="todo"></a> One-Shot Free-View Neural Talking-Head Synthesis for Video Conferencing (**arXiv, 2020**) [[paper](http://arxiv.org/abs/2011.15126)] 
- <a name="todo"></a> FACEGAN: Facial Attribute Controllable rEenactment GAN (**WACV, 2020**) [[paper](http://arxiv.org/abs/2011.04439)] 
- <a name="todo"></a> LandmarkGAN: Synthesizing Faces from Landmarks (**arXiv, 2020**) [[paper](http://arxiv.org/abs/2011.00269)] 
- <a name="todo"></a> Fast Bi-layer Neural Synthesis of One-Shot Realistic Head Avatars (**ECCV, 2020**) [[paper](http://arxiv.org/abs/2008.10174)] [[code](https://github.com/saic-violet/bilayer-model)]
- <a name="todo"></a> Mesh Guided One-shot Face Reenactment using Graph Convolutional Networks (**MM, 2020**) [[paper](http://arxiv.org/abs/2008.07783)] 
- <a name="todo"></a> Learning Identity-Invariant Motion Representations for Cross-ID Face Reenactment (**CVPR, 2020**) [[paper](http://openaccess.thecvf.com/content_CVPR_2020/papers/Huang_Learning_Identity-Invariant_Motion_Representations_for_Cross-ID_Face_Reenactment_CVPR_2020_paper.pdf)] 
- <a name="todo"></a> ReenactNet: Real-time Full Head Reenactment (**arXiv, 2020**) [[paper](http://arxiv.org/abs/2006.10500)] 
- <a name="todo"></a> FReeNet: Multi-Identity Face Reenactment (**CVPR, 2020**) [[paper](http://arxiv.org/abs/1905.11805)] [[code](https://github.com/zhangzjn/FReeNet)]
- <a name="todo"></a> FaR-GAN for One-Shot Face Reenactment (**CVPRW, 2020**) [[paper](http://arxiv.org/abs/2005.06402)] 
- <a name="todo"></a> One-Shot Identity-Preserving Portrait Reenactment (**, 2020**) [[paper](http://arxiv.org/abs/2004.12452)] 
- <a name="todo"></a> Neural Head Reenactment with Latent Pose Descriptors (**CVPR, 2020**) [[paper](http://arxiv.org/abs/2004.12000)] [[code](https://github.com/shrubb/latent-pose-reenactment)]
- <a name="todo"></a> ActGAN: Flexible and Efficient One-shot Face Reenactment (**IWBF, 2020**) [[paper](http://arxiv.org/abs/2003.13840)] 
- <a name="todo"></a> Realistic Face Reenactment via Self-Supervised Disentangling of Identity and Pose (**AAAI, 2020**) [[paper](http://arxiv.org/abs/2003.12957)] 
- <a name="todo"></a> First Order Motion Model for Image Animation (**NIPS, 2020**) [[paper](http://arxiv.org/abs/2003.00196)] [[code](https://github.com/AliaksandrSiarohin/first-order-model)]

### 2019
- <a name="todo"></a> FLNet: Landmark Driven Fetching and Learning Network for Faithful Talking Facial Animation Synthesis (**AAAI, 2019**) [[paper](http://arxiv.org/abs/1911.09224)] 
- <a name="todo"></a> MarioNETte: Few-shot Face Reenactment Preserving Identity of Unseen Targets (**AAAI, 2019**) [[paper](http://arxiv.org/abs/1911.08139)] 
- <a name="todo"></a> Any-to-one Face Reenactment Based on Conditional Generative Adversarial Network (**APSIPA, 2019**) [[paper](https://ieeexplore.ieee.org/document/9023328/)] 
- <a name="todo"></a> Make a Face: Towards Arbitrary High Fidelity Face Manipulation (**ICCV, 2019**) [[paper](http://arxiv.org/abs/1908.07191)] 
- <a name="todo"></a> One-shot Face Reenactment (**BMVC, 2019**) [[paper](http://arxiv.org/abs/1908.03251)] [[code](https://github.com/bj80heyue/One_Shot_Face_Reenactment)]
- <a name="todo"></a> Deferred neural rendering: image synthesis using neural textures (**TOG, 2019**) [[paper](https://dl.acm.org/doi/10.1145/3306346.3323035)] 
- <a name="todo"></a> Animating Arbitrary Objects via Deep Motion Transfer (**CVPR, 2019**) [[paper](https://arxiv.org/abs/1812.08861)] [[code](https://github.com/AliaksandrSiarohin/monkey-net)]

### 2018
- <a name="todo"></a> GANimation: Anatomically-aware Facial Animation from a Single Image (**ECCV, 2018**) [[paper](http://arxiv.org/abs/1807.09251)] [[code](https://github.com/albertpumarola/GANimation)]
- <a name="todo"></a> ReenactGAN: Learning to Reenact Faces via Boundary Transfer (**ECCV, 2018**) [[paper](http://arxiv.org/abs/1807.11079)] [[code](https://github.com/wywu/ReenactGAN)]
- <a name="todo"></a> Deep Video Portraits (**SIGGRAPH, 2018**) [[paper](http://arxiv.org/abs/1805.11714)] 
- <a name="todo"></a> X2Face: A Network for Controlling Face Generation Using Images, Audio, and Pose Codes (**ECCV, 2018**) [[paper](http://link.springer.com/10.1007/978-3-030-01261-8_41)] [[code](https://github.com/oawiles/X2Face)]

### 2016

- <a name="todo"></a> Face2Face: Real-time Face Capture and Reenactment of RGB Videos (**CVPR, 2016**) [[paper](http://www.graphics.stanford.edu/~niessner/papers/2016/1facetoface/thies2016face.pdf)]










